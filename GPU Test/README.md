# Code Test GPU and CPU

This coolab have a code for speed test of GPU and CPU by librery pythorch and cuda, besides test use libraries math.


## PyTorch `Librery Torch`

PyTorch is an optimized tensor library for deep learning using GPUs and CPUs. This is machine learning framework based on the Torch library, used for applications such as computer vision and natural language processing,[7] originally developed by Meta AI and now part of the Linux Foundation umbrella.It is free and open-source software released under the modified BSD license. Although the Python interface is more polished and the primary focus of development, PyTorch also has a C++ interface.

A number of pieces of deep learning software are built on top of PyTorch, including Tesla Autopilot, Uber's Pyro, Hugging Face's Transformers, PyTorch Lightning, and Catalyst.

PyTorch provides two high-level features:
* Tensor computing (like NumPy) with strong acceleration via graphics processing units (GPU)
* Deep neural networks built on a tape-based automatic differentiation system

![f5f772d1-1852-4446-a61f-c661c9354887](https://github.com/FabrizzioCastiglione/Coolab/assets/68827543/3257d128-8df9-4de4-9ca4-8458c788a90d)


## Nvidia `CUDA`

CUDA (or Compute Unified Device Architecture) is a proprietary and closed source parallel computing platform and application programming interface (API) that allows software to use certain types of graphics processing units (GPUs) for general purpose processing, an approach called general-purpose computing on GPUs (GPGPU). CUDA is a software layer that gives direct access to the GPU's virtual instruction set and parallel computational elements, for the execution of compute kernels.

CUDA is designed to work with programming languages such as C, C++, and Fortran. This accessibility makes it easier for specialists in parallel programming to use GPU resources, in contrast to prior APIs like Direct3D and OpenGL, which required advanced skills in graphics programming. CUDA-powered GPUs also support programming frameworks such as OpenMP, OpenACC and OpenCL; and HIP by compiling such code to CUDA.


### Numba

Numba is an open-source JIT compiler that translates a subset of Python and NumPy into fast machine code using LLVM, via the llvmlite Python package. It offers a range of options for parallelising Python code for CPUs and GPUs, often with only minor code changes.

Numba was started by Travis Oliphant in 2012 and has since been under active development at its repository in GitHub with frequent releases. The project is driven by developers at Anaconda, Inc., with support by DARPA, the Gordon and Betty Moore Foundation, Intel, Nvidia and AMD, and a community of contributors on GitHub.

![1_YYkTK8mfxUIuB4sF92qXHg](https://github.com/FabrizzioCastiglione/Coolab/assets/68827543/419c2169-895e-49e0-b517-a2706944e245)
